{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üõ†Ô∏è Notebook 02: Preprocessing & Feature Engineering Avanzato\n",
    "\n",
    "**Obiettivo:** Trasformare i dati grezzi esplorati nell'EDA in un dataset pronto per l'addestramento dei modelli di Machine Learning, risolvendo le criticit√† emerse (skewness, sbilanciamento, non-linearit√†).\n",
    "\n",
    "### üöÄ Roadmap delle Attivit√†\n",
    "Basandoci sulle evidenze del *Notebook 01*, implementeremo le seguenti strategie:\n",
    "\n",
    "1.  **Target Engineering (6 ‚Üí 3 Classi):** Accorperemo le classi per risolvere lo sbilanciamento estremo (<1% Hazardous) e migliorare la separabilit√†.\n",
    "2.  **Feature Selection:** Esclusione rigorosa di `AQI Value` per evitare *Data Leakage*.\n",
    "3.  **Log-Trasformazione:** Applicazione di `log1p` su CO, NO2 e PM2.5 per correggere la skewness elevata (> 3.0) e aiutare i modelli lineari.\n",
    "4.  **Domain-Driven Feature Engineering:** Creazione di nuove variabili basate sulla chimica atmosferica (es. *Traffic Index*, *Smog Index*) per catturare interazioni non lineari.\n",
    "5.  **Stratified Split:** Suddivisione Train/Val/Test che rispetti rigorosamente le proporzioni delle classi di rischio.\n"
   ],
   "id": "198167306a390136"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T23:33:24.187230200Z",
     "start_time": "2025-12-25T23:33:24.104071300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Configurazione ambiente\n",
    "output_dir = '../output'\n",
    "data_dir = '../data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Caricamento Dataset\n",
    "df = pd.read_csv(f'{data_dir}/global_air_pollution_dataset.csv')\n",
    "print(f\"Dataset caricato: {df.shape[0]} righe, {df.shape[1]} colonne\")\n"
   ],
   "id": "709de01b9cf07d11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset caricato: 23463 righe, 12 colonne\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Definizione del nuovo target (3 classi)\n",
    "\n",
    "Dopo l'EDA abbiamo visto che le 6 classi originali (`AQI Category`) sono fortemente sbilanciate, in particolare **Very Unhealthy** e **Hazardous** hanno meno del 2% dei campioni.\n",
    "\n",
    "Per ottenere metriche pi√π affidabili, aggreghiamo le classi in 3 livelli di rischio:\n",
    "\n",
    "- **Safe** ‚Üí Good\n",
    "- **Acceptable** ‚Üí Moderate\n",
    "- **Hazardous** ‚Üí Unhealthy for Sensitive Groups, Unhealthy, Very Unhealthy, Hazardous\n",
    "\n",
    "Questa scelta mantiene il significato clinico delle classi e rende il problema pi√π adatto al training ML.\n"
   ],
   "id": "968622c2979d65b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T23:33:24.217281900Z",
     "start_time": "2025-12-25T23:33:24.189569400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mappatura semantica\n",
    "mapping_3_classes = {\n",
    "    'Good': 'Safe',\n",
    "    'Moderate': 'Acceptable',\n",
    "    'Unhealthy for Sensitive Groups': 'Hazardous',\n",
    "    'Unhealthy': 'Hazardous',\n",
    "    'Very Unhealthy': 'Hazardous',\n",
    "    'Hazardous': 'Hazardous'\n",
    "}\n",
    "\n",
    "# Applicazione mapping\n",
    "df['AQI_Class_Label'] = df['AQI Category'].map(mapping_3_classes)\n",
    "\n",
    "# Encoding numerico per i modelli (0, 1, 2)\n",
    "class_map = {'Safe': 0, 'Acceptable': 1, 'Hazardous': 2}\n",
    "df['AQI_Class_Encoded'] = df['AQI_Class_Label'].map(class_map)\n",
    "\n",
    "# Verifica distribuzione\n",
    "print(\"DISTRIBUZIONE NUOVO TARGET:\")\n",
    "print(df['AQI_Class_Label'].value_counts(normalize=True).mul(100).round(2))\n"
   ],
   "id": "b75977f21ff25255",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIBUZIONE NUOVO TARGET:\n",
      "AQI_Class_Label\n",
      "Safe          42.35\n",
      "Acceptable    39.34\n",
      "Hazardous     18.31\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Feature Engineering & Trasformazioni\n",
    "\n",
    "In questa fase arricchiamo il dataset per aiutare i modelli a catturare pattern complessi.\n",
    "\n",
    "### A. Gestione della Skewness (Log-Trasformazione)\n",
    "Il *Notebook 01* ha mostrato che **CO** (Skew=23.0) e **PM2.5** hanno distribuzioni a coda lunga. I modelli lineari (Logistic Regression) soffrono questi outlier.\n",
    "*   **Azione:** Applichiamo `np.log1p(x)` (logaritmo naturale di x+1) per \"comprimere\" i picchi e rendere la distribuzione pi√π gaussiana.\n",
    "\n",
    "### B. Nuove Feature \"Chimiche\"\n",
    "Le correlazioni lineari tra inquinanti sono basse (<0.5). Creiamo feature combinate per catturare fenomeni specifici:\n",
    "1.  **Traffic Index (`CO * NO2`):** Entrambi sono marker tipici della combustione veicolare. Un alto valore congiunto indica traffico intenso.\n",
    "2.  **Smog Index (`Ozone * NO2`):** L'ozono troposferico si forma spesso dalla reazione degli ossidi di azoto col sole.\n",
    "3.  **Max Pollutant:** Poich√© l'AQI √® definito dal valore peggiore tra gli inquinanti, estraiamo esplicitamente questo valore massimo.\n",
    "4.  **High PM2.5 Flag:** Una soglia binaria (PM2.5 > 100) per segnalare esplicitamente la zona di pericolo, aiutando i modelli a trovare il \"gradino\" critico.\n"
   ],
   "id": "b685ce0fa96038e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T23:33:24.264809700Z",
     "start_time": "2025-12-25T23:33:24.217281900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Selezione Feature Base (NO AQI Value per evitare Leakage)\n",
    "base_features = ['CO AQI Value', 'Ozone AQI Value', 'NO2 AQI Value', 'PM2.5 AQI Value']\n",
    "X = df[base_features].copy()\n",
    "y = df['AQI_Class_Encoded']\n",
    "\n",
    "print(f\"Features base: {base_features}\")\n",
    "\n",
    "# 2. Log-Trasformazione (Skewness reduction)\n",
    "for col in base_features:\n",
    "    X[f'log_{col}'] = np.log1p(X[col])\n",
    "\n",
    "# 3. Feature Engineering Avanzato\n",
    "# Interazioni chimiche\n",
    "X['Traffic_Index'] = X['CO AQI Value'] * X['NO2 AQI Value']\n",
    "X['Smog_Index'] = X['Ozone AQI Value'] * X['NO2 AQI Value']\n",
    "\n",
    "# Logiche di dominio (AQI calculation logic)\n",
    "X['Max_Pollutant'] = X[base_features].max(axis=1)\n",
    "X['Pollutant_Range'] = X[base_features].max(axis=1) - X[base_features].min(axis=1)\n",
    "\n",
    "# Soglie critiche (Domain Knowledge)\n",
    "X['High_PM25_Flag'] = (X['PM2.5 AQI Value'] > 100).astype(int)\n",
    "\n",
    "print(f\"‚úÖ Totale Features create: {X.shape[1]}\")\n",
    "print(f\"Lista: {list(X.columns)}\")"
   ],
   "id": "2a69797b77c3e477",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features base: ['CO AQI Value', 'Ozone AQI Value', 'NO2 AQI Value', 'PM2.5 AQI Value']\n",
      "‚úÖ Totale Features create: 13\n",
      "Lista: ['CO AQI Value', 'Ozone AQI Value', 'NO2 AQI Value', 'PM2.5 AQI Value', 'log_CO AQI Value', 'log_Ozone AQI Value', 'log_NO2 AQI Value', 'log_PM2.5 AQI Value', 'Traffic_Index', 'Smog_Index', 'Max_Pollutant', 'Pollutant_Range', 'High_PM25_Flag']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Suddivisione Stratificata (Train / Val / Test)\n",
    "\n",
    "Dato che la classe *Hazardous* rappresenta circa il 18% del dataset, un *random split* semplice potrebbe creare set di Test dove questa classe √® sottorappresentata, falsando la valutazione.\n",
    "\n",
    "**Soluzione:** Usiamo `stratify=y`.\n",
    "Questo garantisce che la proporzione (Safe 42% / Acceptable 40% / Hazardous 18%) sia identica in tutti e tre i set:\n",
    "*   **Training Set (70%):** Per addestrare i modelli.\n",
    "*   **Validation Set (15%):** Per il tuning degli iperparametri.\n",
    "*   **Test Set (15%):** Per la valutazione finale (mai visto dai modelli).\n"
   ],
   "id": "37225f060c4d5a61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T23:33:24.309471900Z",
     "start_time": "2025-12-25T23:33:24.269322300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split 1: Train (70%) vs Temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split 2: Validation (15%) vs Test (15%) - (met√† del 30% restante)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dimensione Train: {X_train.shape} (70%)\")\n",
    "print(f\"Dimensione Val:   {X_val.shape}   (15%)\")\n",
    "print(f\"Dimensione Test:  {X_test.shape}  (15%)\")\n"
   ],
   "id": "7636b95f0c051bad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione Train: (16424, 13) (70%)\n",
      "Dimensione Val:   (3519, 13)   (15%)\n",
      "Dimensione Test:  (3520, 13)  (15%)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Standardizzazione (Scaling)\n",
    "\n",
    "I modelli come SVM e Regressione Logistica (e in parte anche le Reti Neurali) sono sensibili alla scala delle feature.\n",
    "*   *Esempio:* `Traffic_Index` pu√≤ arrivare a 10.000, mentre `log_CO` arriva a 5. Senza scaling, il modello darebbe peso solo al Traffic Index.\n",
    "\n",
    "**Procedura Corretta:**\n",
    "Usiamo `StandardScaler` (Z-Score normalization).\n",
    "‚ö†Ô∏è **Importante:** Il fit (`calcolo media/std`) viene fatto **SOLO sul Training Set** per evitare *Data Leakage*. Validation e Test vengono trasformati usando le statistiche del Train.\n"
   ],
   "id": "97fc1347844b16f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T23:33:24.347310700Z",
     "start_time": "2025-12-25T23:33:24.311472400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit solo su Train\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "\n",
    "# Transform su Val e Test\n",
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Reset degli indici per allineamento\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Salvataggio finale\n",
    "data_packet = {\n",
    "    'X_train': X_train_scaled, 'y_train': y_train,\n",
    "    'X_val': X_val_scaled, 'y_val': y_val,\n",
    "    'X_test': X_test_scaled, 'y_test': y_test,\n",
    "    'class_map': class_map,\n",
    "    'feature_names': list(X.columns)\n",
    "}\n",
    "\n",
    "outfile = f'{data_dir}/processed_data.pkl'\n",
    "with open(outfile, 'wb') as f:\n",
    "    pickle.dump(data_packet, f)\n",
    "\n",
    "print(f\"‚úÖ Dataset processato salvato in: {outfile}\")\n",
    "print(\"Pronto per il Notebook 03 (Modellazione)\")\n"
   ],
   "id": "b742167cba6f90c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset processato salvato in: ../data/processed_data.pkl\n",
      "Pronto per il Notebook 03 (Modellazione)\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
